<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>First Attempt</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Machine Learning CipherText</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Overview</a>
</li>
<li>
  <a href="data-overview.html">Data</a>
</li>
<li>
  <a href="f-attempt.html">First Attempt</a>
</li>
<li>
  <a href="s-attempt.html">Second Attempt</a>
</li>
<li>
  <a href="t-attempt.html">Third Attempt</a>
</li>
<li>
  <a href="conclusion.html">Conclusion</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">First Attempt</h1>

</div>


<div id="first-attempt" class="section level2">
<h2>First Attempt</h2>
<p>The first attempt at analyzing the text included tabulating:</p>
<ul>
<li>Using the entire train (108,757 rows) and test1 (27,158) including padded characters.</li>
<li>The total number of characters per line (plain text adjusted for padding)
<ul>
<li>This figure should help match groupings of plain text and potential cipher text matches. While the largest population for both populations is 100 characters, it could highlight patterns within the lower volume groups</li>
</ul></li>
<li>The total number of capital letters included in each line.</li>
<li>The total number of lowercase letters included in each line.</li>
<li>The total number of punctuation characters
<ul>
<li>It was determined that punctuation was not encrypted from the plain text.</li>
<li>However, the cipher text data includes additional punctuation as they are also included in the random character padding.</li>
</ul></li>
<li>Generalized individual character frequencies by line that are sorted: most frequent to least frequent
<ul>
<li>This included 52 additional variables</li>
<li>Columns were reordered by row to generalize actual characters (since they would be different between the two sets)</li>
</ul></li>
<li>The data sets would be analyzed using H2O DeepLearning Forward Feeding Neural Network and Sklern’s SVM
<ul>
<li>The actual text lines were used for the H2O model as it automatically one-hot encodes categorical variables.</li>
<li>The actual text was removed when building the SVM model</li>
</ul></li>
<li>The index value from the Train data set was added to the test data set to be used as the response variable.
<ul>
<li>The correct index of matching plain/cipher text was used to determine how successful the predictions were.</li>
</ul></li>
<li>The train set consisted of only plain text and the test set consisted only of cipher text (as structured by Kaggle)</li>
</ul>
<p>The complete Python code for this section can be found: <a href="https://github.com/ckornafel/cipherproject/blob/master/code/Cyphertext_machine_learning.py" class="uri">https://github.com/ckornafel/cipherproject/blob/master/code/Cyphertext_machine_learning.py</a></p>
</div>
<div id="examples-of-data-sets" class="section level1">
<h1>Examples of Data sets</h1>
<pre class="python"><code>import pandas as pd
train = pd.read_csv(&#39;pred_train.csv&#39;)
test1 = pd.read_csv(&#39;pred_test1.csv&#39;)

train.head(10)</code></pre>
<pre><code>##      Unnamed: 0  index  ... V51  V52
## 0  ID_ee32b1f8b      0  ...   0    0
## 1  ID_44eedb7fc      1  ...   0    0
## 2  ID_d897c21b7      2  ...   0    0
## 3  ID_808ab9107      3  ...   0    0
## 4  ID_e4f11a02d      4  ...   0    0
## 5  ID_01d606947      5  ...   0    0
## 6  ID_dd3754b2d      6  ...   0    0
## 7  ID_edcc139b7      7  ...   0    0
## 8  ID_c90fdfcbf      8  ...   0    0
## 9  ID_bd5fdcd3f      9  ...   0    0
## 
## [10 rows x 60 columns]</code></pre>
<pre class="python"><code>test1.head(10)</code></pre>
<pre><code>##      Unnamed: 0   index  ... V51  V52
## 0  ID_000109bf8   53340  ...   0    0
## 1  ID_00038f3bd  102608  ...   1    1
## 2  ID_000651dd7   79003  ...   0    0
## 3  ID_000d158bc   93295  ...   0    0
## 4  ID_000ebdcae    1992  ...   0    0
## 5  ID_000f4b9d4  104229  ...   0    0
## 6  ID_00102d01b   97527  ...   1    0
## 7  ID_001c68a6c  101497  ...   0    0
## 8  ID_001d6c9f2   49935  ...   1    1
## 9  ID_0022645df   56708  ...   1    1
## 
## [10 rows x 60 columns]</code></pre>
<p>I also created a smaller sample data set, as the training of certain models errored out after processing too long</p>
<pre class="python"><code>train_sample = train.sample(n=900, random_state=1)
test1_sample = test1[test1[&#39;index&#39;].isin(train_sample[&#39;index&#39;])]

#Vlaidating that all test classes are still in train
test1_sample[&#39;index&#39;].isin(train[&#39;index&#39;]).value_counts()</code></pre>
<pre><code>## True    246
## Name: index, dtype: int64</code></pre>
<p>So the sampled test data set matches the sampled train data set cases - validating by index</p>
<div id="h2o-neural-network-implementation" class="section level2">
<h2>H2O Neural Network Implementation</h2>
<p><img src="a1h2odataload.png" width="100%" /></p>
<p>The two data frames were successfully parsed and converted to H2O frame types.</p>
</div>
</div>
<div id="issue" class="section level1">
<h1>Issue</h1>
<p>After attempting to run the full train set (108k+) lines in H2O, I discovered that H2O caps the number of classes must be under 1000. Since each plain text sentence was its own class, I needed to adjust and a sampled data frames through instead</p>
<p><img src="a1h2odataload2.png" width="100%" /></p>
<p>As we can see, the Deeplearning model failed out (due to too many classes) and smaller data frames were loaded instead.</p>
</div>
<div id="scoring-history" class="section level1">
<h1>Scoring History</h1>
<p><img src="a1h2oscore1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>As shown in the scoring history plot above, the log_loss for validation dropped steeply after the 1st epoch. I used only 10 epochs to keep the model from crashing, but it does not appear that using a larger number would have improved the results</p>
</div>
<div id="variable-importance" class="section level1">
<h1>Variable Importance</h1>
<p><img src="a1h2ovarimp1.png" width="55%" style="display: block; margin: auto;" /></p>
<p>The model did produce a variable importance chart shows that the most critical variables were letter frequencies (V10 = 10th most frequent character) that measured the larger sentences. Given that the most common length was 100 characters, this would indicate that the longer (and more rare) strings were able to identify the pattern better than the shorter strings. It also shows that the count of punctuation was also important - given that it was already discovered that punctuation was not changed within the cipher used.</p>
<p><img src="a1h2oerror1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>The final output of the model shows that it was not a very accurate and well fitted one. The MSE and RMSE were almost 1 indicating a large amount of error generated.</p>
</div>
<div id="cross-validating-the-sample-model" class="section level1">
<h1>Cross Validating the Sample Model</h1>
<p><img src="a1h2ocrossvalid1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Performing the cross validation did not highlight any possible improvements. The mean accuracy was 0.11% and a corresponding error rate of almost 100%</p>
<p>After adjusting the number of hidden layers and decreasing the epoch, the MSE did not improve (and in some cases actually got worse)</p>
</div>
<div id="grid-best-model-predictions" class="section level1">
<h1>Grid “Best” Model Predictions</h1>
<p><img src="a1h2obestmodpred.png" width="30%" style="display: block; margin: auto;" /></p>
<p>After determining the “best” fit model, I used the sample test set for prediction. The MSE for the prediction achieved a horrible 99.785% error rate (worse than just guessing)</p>
<div id="svm" class="section level2">
<h2>SVM</h2>
<p>When building the SVM model, the complete data set proved to be too large - so the sample data set was used instead. Prior to training the model, the data sets were encoded and scaled using StandardScaler() function. The gamma value was set to “auto”.</p>
</div>
<div id="the-results" class="section level2">
<h2>The Results</h2>
<p><img src="a1svmacc.png" width="60%" style="display: block; margin: auto;" /></p>
<p>After fitting/training the model and then using the sample data sets to predict, the ending accuracy rate was determined to be 0.0 (I have never seen a score so low!)</p>
</div>
<div id="wrap-up" class="section level2">
<h2>Wrap Up</h2>
<p>This attempt showed that, given the train/test data sets, H2O Neural Network and SVM were unable to predict cipher text (given plain text examples) with any useful accuracy. While the NN performed much better than the SVM, it still did not preform as expected.</p>
<p>Thoughts:</p>
<ul>
<li>I believe that using each plain text line as a separate class proved to be a large issue. Unfortunately, reducing the number of examples also decreased the amount of repetitive patterns that could be used for accurate predictions.
<ul>
<li>There is a balance of using too many examples with too many classes and providing enough examples to adequately train the model.</li>
</ul></li>
<li>Using a custom embedding scheme represented numerical patterns, but it appears that these measurements did not provide enough data for machine learning to recognize patterns.</li>
<li>The results of the SVM (0%) were surprising as I was expecting anything else given that there are distinct character length groups represented in the data set. Although, not a powerful measurement, I would have expected some benefit.</li>
<li>I believe that there is an issue of using only plain text in the training set as it does not provide corresponding cipher text examples for the model to compare. There was a large amount of manual data exploration performed before building the test/train sets that a few examples could have been included.
<ul>
<li>I was able to identify a few large length matches which I could have added to the known “training” data.</li>
</ul></li>
</ul>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
