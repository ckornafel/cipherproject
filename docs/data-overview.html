<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Data Overview</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Machine Learning CipherText</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Project Overview</a>
</li>
<li>
  <a href="data-overview.html">Data</a>
</li>
<li>
  <a href="f-attempt.html">First Attempt</a>
</li>
<li>
  <a href="s-attempt.html">Second Attempt</a>
</li>
<li>
  <a href="t-attempt.html">Third Attempt</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Data Overview</h1>

</div>


<div id="the-data" class="section level2">
<h2>The Data:</h2>
<p>The data sets that will be used are provided by Kaggle for the closed “Cipher Challenge III” competition. The challenge contained two data sets: a plain text training set and a ciphertext testing set. The plain text set included 108,755 lines of Shakespeare’s plays. The ciphertext set consisted of 108,755 corresponding lines; however, each line was encrypted with a possible, four layers, of known cipher techniques. For this project, I will focus only on the single-layered ciphertext (level 1) with a stretch goal of attempting an additional layer if the models proved to be successful.</p>
<p>These data sets were specifically chosen due to the Shakespearean plain text. Homomorphic encryption allows for the use of encrypted data without the need to unencrypt it, and Shakespeare’s Old English prose can be viewed as a type of encryption when compared to modern English (to a small degree). Therefore, the use of this text provides an “entry-level” step into machine learning using already encrypted data. Again, if successful, including the second later encrypted data could further show machine learning’s ability to recognize patterns in known data.</p>
<p>While the lines of Shakespeare text vary in length, the ciphertext contained alpha-numeric “padding” to increase each sentence/line length to the next 100 characters. This padding introduces a random element that I will need to account for.</p>
<p>The Cipher text Challenge III data can be found: <a href="https://www.kaggle.com/kaggleuser58/cipher-challenge-iii-level-1/data" class="uri">https://www.kaggle.com/kaggleuser58/cipher-challenge-iii-level-1/data</a></p>
</div>
<div id="text-cleaning" class="section level2">
<h2>Text Cleaning</h2>
<p>Typically, several text “cleaning” techniques would be applied to the text prior to exploring to focus attention only on key elements. Cleaning would include the removal of punctuation, stop words, and capitalization (among other processes). However, since each character (including capitals, punctuation, etc.) may represent a crucial pattern in the encrypted text (e.g. an “a” may be translated to a “!”) no cleaning will be performed. Additionally, the removal of stop words (typically the most frequent) could reduce the size of potential patterns within the text data, complicating the training/prediction process.</p>
</div>
<div id="loading-and-exploring-the-data" class="section level1">
<h1>Loading and Exploring the Data</h1>
<p>Due to the “closed” status of the Kaggle Challenge and the possibility that the data would become unobtainable, copies of each data set was added to the Git Repository.</p>
</div>
<div id="loading-the-libraries" class="section level1">
<h1>Loading the Libraries</h1>
</div>
<div id="loading-the-data" class="section level1">
<h1>Loading the Data</h1>
<pre class="r"><code>#Loading the Data 
##Datasets have been copied to the website
train &lt;- read.csv(&quot;https://raw.githubusercontent.com/ckornafel/cyphertext/master/ciphertext-challenge-iii/train.csv&quot;,
                 stringsAsFactors = FALSE)
test &lt;- read.csv(&quot;https://github.com/ckornafel/cyphertext/raw/master/ciphertext-challenge-iii/test.csv&quot;,
                 stringsAsFactors = FALSE)</code></pre>
</div>
<div id="plain-text-data-set" class="section level1">
<h1>Plain text Data set</h1>
<p>I am expecting to see three columns: An ID, Plain text, and an Index Value</p>
<pre class="r"><code>head(train[order(train$index),],5)</code></pre>
<pre><code>##       plaintext_id                                                   text index
## 15647 ID_ee32b1f8b                 So shaken as we are, so wan with care,     0
## 1415  ID_44eedb7fc             Find we a time for frighted peace to pant,     1
## 47302 ID_d897c21b7         And breathe short-winded accents of new broils     2
## 79236 ID_808ab9107 KING HENRY IV: To be commenced in strands afar remote.     3
## 42715 ID_e4f11a02d              No more the thirsty entrance of this soil     4</code></pre>
<p>As expected, the training data set contains three columns, the plain text id, the Shakespearean plain text, and the index key. The plain text sample shows that each line/row of text could be partial examples of play lines, including randomly included titles. It does appear that some of the text can be grouped by certain whole Shakespearean works (King Henry) and broken out by scene line. Since the first part of King Henry IV contains 33 lines, I wanted to know what the next block of text might include.</p>
<pre class="r"><code>train[which(train$index &gt; 33 &amp; train$index &lt; 39),]</code></pre>
<pre><code>##        plaintext_id                                                       text
## 11616  ID_4228ba5f9    WESTMORELAND: A post from Wales loaden with heavy news,
## 32606  ID_0ea0e4451                     And many limits of the charge set down
## 34473  ID_2465ca5d4 WESTMORELAND: But yesternight: when all athwart there came
## 54787  ID_3cb55c6f4                  Leading the men of Herefordshire to fight
## 103586 ID_53eaea329                  Whose worst was, that the noble Mortimer,
##        index
## 11616     36
## 32606     34
## 34473     35
## 54787     38
## 103586    37</code></pre>
<p>Westmoreland is the next section of King Henry IV after King Henry’s part (scene I) - it appears that the plain text is organized as multiple plays and each line represents one line of plain text.</p>
<pre class="r"><code>length(unique(train$text))</code></pre>
<pre><code>## [1] 108755</code></pre>
<p>108755 unique lines of text matches that total number of rows in the training data set. Therefore, it signifies that there are no repeated lines which could complicate dicphering the cyphertext, given that there are multiple ciphers applied to the entire set.</p>
</div>
<div id="cipher-text" class="section level1">
<h1>Cipher text</h1>
<pre class="r"><code>str(test)</code></pre>
<pre><code>## &#39;data.frame&#39;:    108755 obs. of  3 variables:
##  $ ciphertext_id: chr  &quot;ID_4a6fc1ea9&quot; &quot;ID_9460d3380&quot; &quot;ID_ac39fd360&quot; &quot;ID_d089e3234&quot; ...
##  $ ciphertext   : chr  &quot;H2-t.&#39;HzW$QOSvkPw v)4I1iSECKPX: P ktxjkp qemfl, eq pvt sssid elede btqp sbcly)hVJ9M41hVpx4fKh!vG)-Fh&quot; &quot;Ah1QtVkLNcx7Q6mgvleEAqFIzyZoYkVtiKnd2Yy2t2GmoT4FkAHmS4YCE8n6IRobTMyu6PnCY919kB/UtA0/gg9qYQtIZxM9z/bKvA213y1/Ebe&quot;| __truncated__ &quot;BxBYt00fPc5zQqmls1mAFrVIzihsdFdoiKjdzZ22tWOnoTwGkRnkXIILBs74MxESXsy26vvbY9drlBnNsQgtgAp+Zg9fahMvy/TavQikyyB7HLm&quot;| __truncated__ &quot;AxFVtU0YMcl6R6mlvFKNFbVNziNpYkNtjKLX2Y+wsWShoTkDkRXhXIEDBsz/MxsXWMCv/v/Xa9Z+hxnBsQY6kg18ZAtKfhQuyPbLqwel0y1sG7+&quot;| __truncated__ ...
##  $ difficulty   : int  1 4 4 4 3 1 2 3 4 3 ...</code></pre>
<p>The test (cyphertext) data set also contains three variables: ciphertext id, ciphertext, and difficulty. The difficulty value indicates the number of ciphers used on the plain text. E.g. level one indicates that a single cipher was applied, level two indicates that an additional cipher was applied to the first ciphertext, etc.</p>
</div>
<div id="splitting-the-test-data-set-into-four-levels" class="section level1">
<h1>Splitting the Test Data set into Four Levels</h1>
<pre class="r"><code>test1&lt;- test[test$difficulty==1,]
test2&lt;- test[test$difficulty==2,]
test3&lt;- test[test$difficulty==3,]
test4&lt;- test[test$difficulty==4,]
rm(test) #Conserving memory
head(test1$ciphertext) #Viewing the Level 1 CipherText</code></pre>
<pre><code>## [1] &quot;H2-t.&#39;HzW$QOSvkPw v)4I1iSECKPX: P ktxjkp qemfl, eq pvt sssid elede btqp sbcly)hVJ9M41hVpx4fKh!vG)-Fh&quot;
## [2] &quot;Pv4n2iv9M[[I39w5dBz&#39;YURX-R-CIopea, adeld Sirsav: md lvt lggw cppxfsxtc.83 !NWeC xTrHd,7X:X)937$zf,(P&quot;
## [3] &quot;0W,jz:pH(z9xIENX5o[VM,!zma)]P5M rydi dnf bwhfltq, qsh H miv ma jpuayh,,(Fb0gO5T]q.q4T3bt$5aJK1$)plKq&quot;
## [4] &quot;bN0pTfe9HBIzGH[uU$g?hBd.kmIW7j.qXe kld prtht ktjt-glvchyk wdlaxmpwi-ogKAan17gjP.QJd[w1- rui]xICalV9v&quot;
## [5] &quot;CPuqjMj5$tOcHNthUki.&#39;9LMNaAOErbptj ssmi rnvekw, qerf khynmete weupvthrr,rMJjGs$XVstbh 7,JRf)M9cI3Ix[&quot;
## [6] &quot;j-?xWsIxuFxx1bgN,,:,VlU[-w&#39;F,LM[)nxyX]X baybc iibk qshapeh&#39;s.i-:XI 7Q11to$GvVMvbYPb0rF,M1V3wwzFi-G5J&quot;</code></pre>
<div id="termswords" class="section level2">
<h2>Terms/Words</h2>
<p>Both data sets contained lines of text (sentences) which could be broken down into smaller text-items. For the next part, I will be focusing on the words/terms which comprise each of the text lines. Perhaps there may be some pattern that I can use to create numeric vectors for the machine learning algorithms.</p>
<p><img src="Train_term_freq.png" width="70%" /></p>
<p>It appears that there are only a small subset of terms (approx 7) which appear with high frequency. One term appears over 25,000 times but the next most frequent term drops to below 10,000 occurrences in the complete Shakespearean text. There are 27937 terms that appear only once in the Shakespeare text. This highlights that slightly more than half (51.33%) of the entire set of terms are unique combinations of letters/punctuation.</p>
</div>
</div>
<div id="most-frequent-terms-in-the-train-plain-text-set" class="section level1">
<h1>Most Frequent Terms in the Train (Plain text) Set</h1>
<p><img src="train_wc.png" width="100%" /> The most frequent Shakespeare terms are similar to those found in modern English (e.g. and, the, not, etc.). Normally, in text mining exercises, these common (stop) words would be removed in order to focus on the more impactful words in the corpus. However, since I am working with cyphertext every word (and punctuation) could be represented in the ciphertext and therefore needs to remain in the plain text.</p>
</div>
<div id="most-frequent-terms-in-the-test-cipher-text-set" class="section level1">
<h1>Most Frequent Terms in the Test (Cipher text) Set</h1>
<p><img src="test1_wc.png" width="100%" /> The most frequent terms in the test1 data set appear to be similar in length (short) to the plain text frequent words. Although, there seem to a few words (e.g. xwd, ssiflt) that have much more frequency. This is because the training set is only a quarter of the size of the training set. There are no terms in test 3 which appear only once. The lowest frequency of occurrence are two terms which appear twice and three times in the cipher text. Given the large volume of individual number combinations, it may indicate that they represent letter pairs or phonetic sounds instead of whole terms.</p>
</div>
<div id="comparing-word-frequency-between-train-and-test" class="section level1">
<h1>Comparing Word Frequency between Train and Test</h1>
<pre class="r"><code>WordCount &lt;- function(x){
  return(length(unlist(strsplit(as.character(x), &quot;\\W+&quot;))))
  
}
train$num_term&lt;-sapply(train$text, WordCount)
table(train$num_term)</code></pre>
<pre><code>## 
##     1     2     3     4     5     6     7     8     9    10    11    12    13 
##   416  2233  3441  5308  5936  7881 12344 18744 21049 16569  8924  3991  1303 
##    14    15    16    17    18    19    20    21    22    23    24    25    26 
##   349    92    32    24    17     6    11     7     4     7     9     5     7 
##    27    28    29    30    31    32    33    34    35    36    40    43    47 
##     4     3     3     5     4     1     2     3     5     2     1     1     1 
##    48    49    52    56    57    67    68    76   123   147   168 
##     1     1     1     1     1     1     1     1     1     1     1</code></pre>
<pre class="r"><code>test1$num_term&lt;-sapply(test1$ciphertext, WordCount)
table(test1$num_term)</code></pre>
<pre><code>## 
##    7    8    9   10   11   12   13   14   15   16   17   18   19   20   21   22 
##    2   15   29  105  269  613 1200 2169 3295 4037 4466 3969 3009 1999 1126  516 
##   23   24   25   26   27   28   29   30   31   32   33   34   35   44   45   47 
##  185   79   27    9    5    1    5    4    5    4    2    1    2    2    1    1 
##   49   50   51   61   76 
##    1    2    1    1    1</code></pre>
<p>It does not appear that the count of terms for each section of Shakespeare Text correlates well with the count of terms from each of the cipher texts. Those term counts that do align (e.g. one instance of a 49-term length Shakespeare text) also appear in multiple cipher texts (e.g one instance of a 49-term Test 1 text and one instance of a 49-term Test 2 text). Given the assumption that there is no overlap of cipher to plain texts, it would appear that spaces may not term separators in the cipher texts.</p>
<p>Additionally, there are 416 instances of a single-term Shakespeare text but the smallest number of cipher text terms is seven in both test1 and test2 sets. Either these single-term texts are hidden in test3 and test4, or another indication that spaces are not term separators in the cipher texts.</p>
</div>
<div id="groups-of-terms" class="section level1">
<h1>Groups of Terms</h1>
<pre class="r"><code>term_freq &lt;- train %&gt;%
  group_by(num_term) %&gt;%
  summarise(counts = n())

ggplot(head(term_freq,20), aes(x=num_term, y = counts ))+
  geom_bar(fill = &quot;steelblue&quot;, stat = &quot;identity&quot;)+
  theme_minimal()</code></pre>
<p><img src="data-overview_files/figure-html/unnamed-chunk-9-1.png" width="672" /> It looks like the training set is mainly comprised of short (&lt;15) worded terms. However, given that this set represents all four cipher levels and we are only focusing on one, the actual distribution of the reduced set may be smaller.</p>
<div id="characters" class="section level2">
<h2>Characters</h2>
<p>While the above section explored the individual words/terms within each line of text. This next section will dive into the individual characters which make-up those words/terms.</p>
</div>
</div>
<div id="a-quick-check-to-verify-that-the-same-characters-are-used-for-train-and-test1" class="section level1">
<h1>A quick check to verify that the same characters are used for train and test1</h1>
<pre class="r"><code>all_text_train &lt;- paste(train$text, collapse= &quot;&quot;)
all_text_test1 &lt;- paste(test1$ciphertext, collapse = &quot;&quot;)
uniq_chr_train &lt;-as.vector(unique(strsplit(all_text_train, &quot;&quot;)[[1]]))
uniq_chr_test1 &lt;-as.vector(unique(strsplit(all_text_test1, &quot;&quot;)[[1]]))

sort(uniq_chr_train) == sort(uniq_chr_train)</code></pre>
<pre><code>##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</code></pre>
<pre class="r"><code>sort(uniq_chr_train) == sort(uniq_chr_test1)</code></pre>
<pre><code>##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</code></pre>
<p>It is known that the plain text and ciphertext did not contain any unique characters and were comprised of alpha letters (upper/lower case), punctuation, and spaces. This confirms that the two data sets did not include characters that were not also used in the other. Hopefully this will make it easier for the machine learning models to identify patterns.</p>
<p><img src="letter_comp.png" width="90%" /></p>
<p>The comparison of the characters highlights a potential substitution cipher being used. I’ve included the second layered ciphertext set for comparison. According to this chart, it could be assumed that the space character is not changed when encrypted. This means that individual words have the same separator (space) after encryption. Additionally, this plot could identify that all plain text e’s are exchanged for ciphertext s’s. Another possible assumption could be made between the level 1 and 2 encryption since the character frequencies are so similar. This could indicate that they are similar cipher techniques but with different rotating letters. It is also noted that punctuation does not appear in the ciphertext frequencies, this could indicate that punctuation marks are not used as substitutions for alpha letters.</p>
</div>
<div id="exploring-the-punctuation-assumption-further" class="section level1">
<h1>Exploring the punctuation assumption further</h1>
<p>The above plot highlights a unique pattern within the ciphertext that indicates that punctuation is not encrypted. <img src="punct_freq.png" width="60%" /></p>
<p>Given the order of frequencies for each punctuation character, it does appear that punctuation remains the same between test and train.</p>
</div>
<div id="examining-character-counts-by-line" class="section level1">
<h1>Examining Character Counts by Line</h1>
<p><img src="chr_cnts.png" width="60%" /></p>
<p>The above plot shows that the majority of the training (plain text) data falls below 100 characters. This indicates that the majority of the corresponding ciphertext includes over 50 additional (random) characters as “padding”. These extra characters will provide a challenge for the ML models as it introduces randomness in any potential pattern for the largest portion of the data set. However, having few examples of longer character lines could help identify the padding scheme which could then be removed (and reduce the randomness).</p>
<p><img src="pad_box.png" width="90%" /></p>
<p>The box plot for the padded character amounts show that the majority of the padding occurs within the 0 - 100 character rows. This group (100) has an average of approx. 60 additional characters added to the Shakespeare text. However, it also has a range of up to 99 additional characters - having the largest spread of padding. The 700, 900, and 1100 (largest) groups have the fewest members and consist of approx 27, 60, and 72 (respectively) additional characters. I assume that the low number of these larger text blocks will compensate for the additional characters when predicting the plain text. The above plot also indicates a large amount of outlying padding characters for the 100-char population. This could highlight a potential issue with the random-factor for the largest group and obscure predictive patterns.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
